{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NPZ\n",
    "using Plots\n",
    "using PaddedViews\n",
    "using ProgressMeter\n",
    "using LinearAlgebra\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = npzread(\"KMNIST/kmnist-train-imgs.npz\")\n",
    "train_labels = npzread(\"KMNIST/kmnist-train-labels.npz\")\n",
    "test_dict = npzread(\"KMNIST/kmnist-test-imgs.npz\")\n",
    "test_labels = npzread(\"KMNIST/kmnist-test-labels.npz\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"o\", \"ki\", \"su\", \"tsu\", \"na\", \"ha\", \"ma\", \"ya\", \"re\", \"wo\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images:\t(28, 28, 1, 60000)\t\t labels: (60000,)\n",
      "Test images:\t(28, 28, 1, 10000)\t\t labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_y = convert(Vector{Int64}, train_labels[\"arr_0\"])\n",
    "test_y = convert(Vector{Int64}, test_labels[\"arr_0\"])\n",
    "\n",
    "train_x = convert(Array{Float32}, train_dict[\"arr_0\"])/255\n",
    "train_x = permutedims(train_x, (2,3,1))\n",
    "train_x = reshape(train_x, (28,28,1,60000))\n",
    "\n",
    "test_x = convert(Array{Float32}, test_dict[\"arr_0\"])/255\n",
    "test_x = permutedims(test_x, (2,3,1))\n",
    "test_x = reshape(test_x, (28,28,1,10000));\n",
    "\n",
    "println(\"Train images:\\t\", size(train_x), \"\\t\\t labels: \", size(train_y))\n",
    "println(\"Test images:\\t\", size(test_x), \"\\t\\t labels: \", size(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graf obliczeniowy -- węzły"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type Node end\n",
    "abstract type Operator <: Node end\n",
    "\n",
    "mutable struct Variable{N} <: Node\n",
    "    name::String\n",
    "    output::Array{Float64, N}\n",
    "    gradient::Array{Float64, N}\n",
    "    v₁::Array{Float64, N}\n",
    "    v₂::Array{Float64, N}\n",
    "    Variable(N, output; name = \"?\") = new{N}(name, output, zeros(size(output)), zeros(size(output)), zeros(size(output)))\n",
    "end\n",
    "\n",
    "mutable struct NodeOperator{F} <: Operator\n",
    "    name::String\n",
    "    inputs\n",
    "    output\n",
    "    gradient\n",
    "    NodeOperator(fun, inputs...; name = \"?\") = new{typeof(fun)}(name, inputs, [], [])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show (generic function with 387 methods)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: show, summary\n",
    "show(io::IO, x::NodeOperator{F}) where {F} = print(io, \"op \", \"(\", F, \")\");\n",
    "show(io::IO, x::Variable) = begin\n",
    "    print(io, \"var \", x.name);\n",
    "    print(io, \"\\n ┣━ ^ \"); summary(io, x.output)\n",
    "    print(io, \"\\n ┗━ ∇ \");  summary(io, x.gradient)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graf obliczeniowy -- funkcje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie grafu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_graph (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function visit(node::Node, visited::Set, order::Vector)\n",
    "    if node ∉ visited\n",
    "        push!(visited, node)\n",
    "        push!(order, node)\n",
    "    end\n",
    "end\n",
    "\n",
    "function visit(node::Operator, visited::Set, order::Vector)\n",
    "    if node ∉ visited\n",
    "        for input in node.inputs\n",
    "            visit(input, visited, order)\n",
    "        end\n",
    "        push!(visited, node)\n",
    "        push!(order, node)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function create_graph(root::Node)\n",
    "    visited = Set()\n",
    "    order = Vector()\n",
    "    visit(root, visited, order)\n",
    "    return order\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przejście w przód z zerowaniem gradientu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_gradient!(node::Variable) = fill!(node.gradient, 0)\n",
    "zero_gradient!(node::Operator) = node.gradient = []\n",
    "\n",
    "compute!(node::Variable) = nothing\n",
    "compute!(node::Operator) = node.output = forward(node, [input.output for input in node.inputs]...)\n",
    "\n",
    "function forward!(order::Vector)\n",
    "    for node in order\n",
    "        compute!(node)\n",
    "        zero_gradient!(node)\n",
    "    end\n",
    "    \n",
    "    return last(order).output\n",
    "end    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przejście w tył"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward! (generic function with 3 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update!(node::Node, gradient) = if isempty(node.gradient)\n",
    "    node.gradient = gradient else node.gradient += gradient\n",
    "end\n",
    "\n",
    "function backward!(order::Vector; seed = 1.0)\n",
    "    result = last(order)\n",
    "    result.gradient = seed\n",
    "    \n",
    "    for node in reverse(order)\n",
    "        backward!(node)\n",
    "    end\n",
    "end\n",
    "\n",
    "backward!(node::Variable) = nothing\n",
    "\n",
    "function backward!(node::Operator)\n",
    "    gradients = backward(node, [input.output for input in node.inputs]..., node.gradient)\n",
    "    for (input, gradient) in zip(node.inputs, gradients)\n",
    "        update!(input, gradient)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieć i warstwy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicja struktur parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ConvParams\n",
    "    kernels::Variable\n",
    "    bias::Variable\n",
    "end\n",
    "\n",
    "mutable struct DenseParams\n",
    "    weights::Variable\n",
    "    bias::Variable\n",
    "end\n",
    "\n",
    "mutable struct CNNParams\n",
    "    conv1::ConvParams\n",
    "    conv2::ConvParams\n",
    "    dense1::DenseParams\n",
    "    dense2::DenseParams\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warstwa konwolucyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(x::Node, k::Node, b::Node) = NodeOperator(conv_layer, name=\"conv\", x, k, b)\n",
    "\n",
    "forward(::NodeOperator{typeof(conv_layer)}, x, k, b) = let\n",
    "    x_size = size(x)\n",
    "    k_size = size(k)\n",
    "    no_k = floor(Int, sqrt(k_size[2])) - 1\n",
    "    x̂_size = x_size[1] - 4\n",
    "    x_vectorized = zeros(k_size[2], x̂_size^2, x_size[3])\n",
    "    no_patch = 1\n",
    "    for c in 1:x̂_size, r in 1:x̂_size\n",
    "        x_vectorized[:, no_patch, :] = reshape(x[r:(r+no_k), c:(c+no_k), :], (k_size[2], 1, x_size[3]))\n",
    "        no_patch += 1\n",
    "    end\n",
    "    x̂_vectorized = zeros(k_size[1], x̂_size^2)\n",
    "\n",
    "    for i in 1:x_size[3]\n",
    "        x̂_vectorized[:, :] += k * x_vectorized[:, :, i]\n",
    "    end\n",
    "    \n",
    "    x̂_vectorized .+= b\n",
    "\n",
    "    x̂ = zeros(x̂_size, x̂_size, k_size[1])\n",
    "    for i in 1:k_size[1]\n",
    "        x̂[:, :, i] = reshape(x̂_vectorized[i, :], (x̂_size, x̂_size))\n",
    "    end\n",
    "    \n",
    "    return x̂\n",
    "end\n",
    "\n",
    "backward(::NodeOperator{typeof(conv_layer)}, x, k, b, g) = let\n",
    "    x_size = size(x)\n",
    "    k_size = size(k)\n",
    "    no_k = floor(Int, sqrt(k_size[2])) - 1\n",
    "    x̂_size = x_size[1] - 4\n",
    "    x_vectorized = zeros(k_size[2], x̂_size^2, x_size[3])\n",
    "    no_patch = 1\n",
    "    for c in 1:x̂_size, r in 1:x̂_size\n",
    "        x_vectorized[:,no_patch, :] = reshape(x[r:(r+no_k), c:(c+no_k), :], (k_size[2], 1, x_size[3]))\n",
    "        no_patch += 1\n",
    "    end\n",
    "    \n",
    "    g_vectorized = reshape(g, size(g)[1]^2, size(g)[3])\n",
    "    dk = zeros(k_size)\n",
    "    \n",
    "    dk = g_vectorized' * sum(x_vectorized, dims=3)[:,:,1]'\n",
    "    \n",
    "    db = sum(g_vectorized', dims=1)\n",
    "    \n",
    "    g_size = size(g)\n",
    "    g_padded = PaddedView(0, g, (1:(g_size[1]+8), 1:(g_size[1]+8), 1:g_size[3]), (5:(g_size[1]+4), 5:(g_size[1]+4), 1:g_size[3]))\n",
    "    g_pad_vect = zeros(k_size[2], (g_size[1]+4)^2, g_size[3])\n",
    "    no_patch = 1\n",
    "    for c in 1:(g_size[1]+4), r in 1:(g_size[1]+4)\n",
    "        g_pad_vect[:, no_patch, :] = reshape(g_padded[r:(r+no_k), c:(c+no_k), :], (k_size[2], 1, g_size[3]))\n",
    "        no_patch += 1\n",
    "    end\n",
    "    k_reversed = reverse(k, dims=2)\n",
    "    \n",
    "    dx = zeros(g_size[3], (g_size[1]+4)^2)\n",
    "\n",
    "    for i in 1:g_size[3]\n",
    "        dx[:, :] += k_reversed * g_pad_vect[:, :, i]\n",
    "    end\n",
    "    \n",
    "    dx = sum(dx, dims=1)\n",
    "\n",
    "    dx = repeat(reshape(dx, (x_size[1], x_size[1])), 1, 1, x_size[3])\n",
    "    \n",
    "    return tuple(dx, dk, db)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warstwa maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 2 methods)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool_layer(x::Node) = NodeOperator(maxpool_layer, name=\"maxpool\", x)\n",
    "\n",
    "forward(::NodeOperator{typeof(maxpool_layer)}, x) = let\n",
    "    n = floor(Int, size(x)[1]/2) # new size\n",
    "    x̂ = zeros(n, n, size(x)[3])\n",
    "    s = 2 # stride\n",
    "    \n",
    "    for r in 1:n, c in 1:n\n",
    "        x̂[r, c, :] = maximum(x[(r*s-1):(r*s), (c*s-1):(c*s), :], dims=(1,2))\n",
    "    end\n",
    "    \n",
    "    return x̂\n",
    "end\n",
    "\n",
    "backward(::NodeOperator{typeof(maxpool_layer)}, x, g) = let\n",
    "    n = floor(Int, size(x)[1]/2) # new size\n",
    "    s = 2 # stride\n",
    "    x̂ = zeros(size(x))\n",
    "    \n",
    "    for r in 1:n, c in 1:n\n",
    "        idx = argmax(x[(r*s-1):(r*s), (c*s-1):(c*s), :], dims=(1,2))\n",
    "        @views x̂[(r*s-1):(r*s), (c*s-1):(c*s), :][idx] = g[r, c, :]\n",
    "    end\n",
    "    return tuple(x̂)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warstwa flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 3 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(x::Node) = NodeOperator(flatten, name=\"flatten\", x)\n",
    "\n",
    "forward(::NodeOperator{typeof(flatten)}, x) = let\n",
    "    return reshape(x, size(x)[1]*size(x)[2]*size(x)[3])\n",
    "end\n",
    "\n",
    "backward(::NodeOperator{typeof(flatten)}, x, g) = let\n",
    "    return tuple(reshape(g, size(x)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warstwa gęsta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 4 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer(x::Node, w::Node, b::Node) = NodeOperator(dense_layer, name=\"dense\", x, w, b)\n",
    "\n",
    "forward(::NodeOperator{typeof(dense_layer)}, x, w, b) = let\n",
    "    return w * x + b\n",
    "end\n",
    "\n",
    "backward(::NodeOperator{typeof(dense_layer)}, x, w, b, g) = let\n",
    "    return tuple(w' * g, g * x', g)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 5 methods)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(x::Node) = NodeOperator(relu, name=\"relu\", x)\n",
    "\n",
    "forward(::NodeOperator{typeof(relu)}, x) = let\n",
    "    return max.(x, 0)\n",
    "end\n",
    "\n",
    "backward(::NodeOperator{typeof(relu)}, x, g) = let\n",
    "    id_max = findall(a -> a > 0, x)\n",
    "    x̂ = zeros(Float64, size(x))\n",
    "    x̂[id_max] = g[id_max]\n",
    "    return tuple(x̂)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 6 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x::Node) = NodeOperator(softmax, name=\"softmax\", x)\n",
    "\n",
    "forward(::NodeOperator{typeof(softmax)}, x) = let\n",
    "    return exp.(x) ./ sum(exp.(x))\n",
    "end\n",
    "\n",
    "backward(node::NodeOperator{typeof(softmax)}, x, g) = let\n",
    "    y = node.output\n",
    "    J = diagm(y) .- y * y'\n",
    "    tuple(J' * g)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja straty -- cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 7 methods)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_loss(ŷ::Node, y::Node) = NodeOperator(cross_entropy_loss, name=\"cross_entropy_loss\", ŷ, y)\n",
    "\n",
    "forward(::NodeOperator{typeof(cross_entropy_loss)}, ŷ, y) = let\n",
    "    return -log(ŷ[floor(Int, y[1]+1)])\n",
    "end\n",
    "\n",
    "backward(::NodeOperator{typeof(cross_entropy_loss)}, ŷ, y, g) = let\n",
    "    x = zeros(10)\n",
    "    id = floor(Int, y[1]) + 1\n",
    "    x[id] = -1 / ŷ[id] * g\n",
    "    return tuple(x, [0.0])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struktura sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_cnn (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_cnn(x::Variable, y::Variable, params::CNNParams)\n",
    "    x̂ = conv_layer(x, params.conv1.kernels, params.conv1.bias)\n",
    "    x̂ = relu(x̂)\n",
    "    x̂ = maxpool_layer(x̂)\n",
    "    x̂ = conv_layer(x̂, params.conv2.kernels, params.conv2.bias)\n",
    "    x̂ = relu(x̂)\n",
    "    x̂ = maxpool_layer(x̂)\n",
    "    \n",
    "    x̂ = flatten(x̂)\n",
    "    \n",
    "    x̂ = dense_layer(x̂, params.dense1.weights, params.dense1.bias)\n",
    "    x̂ = dense_layer(x̂, params.dense2.weights, params.dense2.bias)\n",
    "    \n",
    "    ŷ = softmax(x̂)\n",
    "    \n",
    "    loss = cross_entropy_loss(ŷ, y)\n",
    "    \n",
    "    return create_graph(loss)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicjalizacja wag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he_weights_init (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function he_weights_init(prev, shape...)\n",
    "    std = sqrt(2.0/prev)\n",
    "    weights = rand(Float64, shape) .*2 .-1\n",
    "    return weights .* std\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalizator -- ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Adam\n",
    "    α::Float64\n",
    "    ε::Float64\n",
    "    m₁::Float64\n",
    "    m₂::Float64\n",
    "    k::Int64\n",
    "    Adam(α=0.001, m₁=0.9, m₂=0.999, ε=1e-8) = new(α, ε, m₁, m₂, 1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_weights! (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_weights!(graph, M::Adam)\n",
    "    m₁, m₂ =  M.m₁, M.m₂\n",
    "    α, ε, k = M.α, M.ε, M.k\n",
    "    for node in graph\n",
    "        if typeof(node) == Variable{1} || typeof(node) == Variable{2} || typeof(node) == Variable{3}\n",
    "            g = node.gradient\n",
    "            v₁ = node.v₁\n",
    "            v₂ = node.v₂\n",
    "            v₁[:] = m₁*v₁ + (1.0 - m₁) * g\n",
    "            v₂[:] = m₂*v₂ + (1.0 - m₂) * g .* g\n",
    "            \n",
    "            v̂₁ = v₁ ./ (1.0 - m₁^k)\n",
    "            v̂₂ = v₂ ./ (1.0 - m₂^k)\n",
    "    \n",
    "            node.output -= α*v̂₁ ./ (sqrt.(v̂₂) .+ ε)\n",
    "        end\n",
    "    end\n",
    "    M.k = k += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicjalizacja parametrów sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = ConvParams(\n",
    "    Variable(2, he_weights_init(28*28, 20,25), name=\"k1\"),\n",
    "    Variable(2, zeros(1,24*24), name=\"b1\")\n",
    ")\n",
    "conv2 = ConvParams(\n",
    "    Variable(2, he_weights_init(12*12*20, 50,25), name=\"k2\"),\n",
    "    Variable(2, zeros(1,8*8), name=\"b2\")\n",
    ")\n",
    "dense1 = DenseParams(\n",
    "    Variable(2, he_weights_init(4*4*50, 500,800), name=\"w3\"),\n",
    "    Variable(1, zeros(500), name=\"b3\")\n",
    ")\n",
    "dense2 = DenseParams(\n",
    "    Variable(2, he_weights_init(500, 10,500), name=\"w4\"),\n",
    "    Variable(1, zeros(10), name=\"b4\")\n",
    ")\n",
    "\n",
    "cnn_params = CNNParams(conv1, conv2, dense1, dense2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validate (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function validate(x, y, graph, val_x, val_y, no_val, count_class, acc_class, e)\n",
    "    correct_val = 0\n",
    "    correct_class = zeros(10)\n",
    "    \n",
    "    for i in 1:no_val\n",
    "        x.output = val_x[:,:,:,i]\n",
    "        y.output = [val_y[i]]\n",
    "        forward!(graph)\n",
    "        pred = argmax(graph[19].output)\n",
    "        if pred == (val_y[i] + 1)\n",
    "            correct_val += 1\n",
    "            correct_class[pred] += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    acc_val = correct_val/no_val\n",
    "    acc_class[:, e] = correct_class ./ count_class\n",
    "    \n",
    "    return (acc_val, acc_class)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_cnn (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_cnn(x, y, graph, adam)\n",
    "    no_train = 1000\n",
    "    epochs = 3\n",
    "\n",
    "    ids = rand(1:60000, no_train)\n",
    "    data_x = train_x[:,:,:,ids]\n",
    "    data_y = train_y[ids]\n",
    "\n",
    "    no_val = 100\n",
    "    ids_val = rand(1:10000, no_val)\n",
    "    val_x = test_x[:,:,:,ids_val]\n",
    "    val_y = test_y[ids_val]\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    losses = zeros(epochs)\n",
    "    count_class = [count(==(i), val_y) for i in 0:9]\n",
    "    acc = zeros(epochs)\n",
    "    acc_class = zeros(10, epochs)\n",
    "    acc_val = 0\n",
    "    correct_val = 0\n",
    "    correct = 0\n",
    "\n",
    "    for e in 1:epochs\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for i in 1:no_train\n",
    "            x.output = data_x[:,:,:,i]\n",
    "            y.output = [data_y[i]]\n",
    "\n",
    "            loss += forward!(graph)\n",
    "            pred = argmax(graph[19].output)\n",
    "            if pred == (data_y[i] + 1)\n",
    "                correct += 1\n",
    "            end\n",
    "\n",
    "            backward!(graph)\n",
    "\n",
    "            update_weights!(graph, adam)\n",
    "        end\n",
    "\n",
    "        losses[e] = loss/no_train\n",
    "        acc[e] = correct/no_train\n",
    "        acc_val, acc_class = validate(x, y, graph, val_x, val_y, no_val, count_class, acc_class, e)\n",
    "\n",
    "        println(\"Epoch: \", e, \"\\tAverage loss: \", round(losses[e], digits=3), \"\\tAverage acc: \", round(acc[e],digits=3), \"\\tAverage val acc: \", round(acc_val, digits=3))\n",
    "    end\n",
    "\n",
    "    println(round.(acc_class[:, epochs], digits=3))\n",
    "\n",
    "    return graph\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tAverage loss: 1.682\tAverage acc: 0.427\tAverage val acc: 0.42\n",
      "Epoch: 2\tAverage loss: 1.021\tAverage acc: 0.663\tAverage val acc: 0.43\n",
      "Epoch: 3\tAverage loss: 0.812\tAverage acc: 0.72\tAverage val acc: 0.46\n",
      "[0.25, 0.25, 0.286, 0.429, 0.273, 0.571, 0.5, 0.556, 0.786, 0.6]\n",
      "Epoch: 1\tAverage loss: 1.543\tAverage acc: 0.537\tAverage val acc: 0.41\n",
      "Epoch: 2\tAverage loss: 1.032\tAverage acc: 0.65\tAverage val acc: 0.47\n",
      "Epoch: 3\tAverage loss: 0.934\tAverage acc: 0.713\tAverage val acc: 0.43\n",
      "[0.286, 0.0, 0.333, 0.455, 0.727, 0.615, 0.727, 0.167, 0.556, 0.286]\n",
      "Epoch: 1\tAverage loss: 1.503\tAverage acc: 0.527\tAverage val acc: 0.47\n",
      "Epoch: 2\tAverage loss: 1.007\tAverage acc: 0.657\tAverage val acc: 0.48\n",
      "Epoch: 3\tAverage loss: 1.046\tAverage acc: 0.64\tAverage val acc: 0.46\n",
      "[0.667, 0.2, 0.273, 0.643, 0.5, 0.571, 0.231, 0.636, 0.625, 0.333]\n",
      "Epoch: 1\tAverage loss: 1.407\tAverage acc: 0.63\tAverage val acc: 0.42\n",
      "Epoch: 2\tAverage loss: 1.03\tAverage acc: 0.647\tAverage val acc: 0.38\n",
      "Epoch: 3\tAverage loss: 0.838\tAverage acc: 0.73\tAverage val acc: 0.35\n",
      "[0.462, 0.25, 0.273, 0.308, 0.455, 0.556, 0.2, 0.364, 0.25, 0.333]\n",
      "  28.297 s (12468522 allocations: 69.78 GiB)\n"
     ]
    }
   ],
   "source": [
    "x = Variable(3, train_x[:,:,:,1], name=\"x\")\n",
    "y = Variable(1, [train_y[1]], name=\"y\")\n",
    "graph = my_cnn(x, y, cnn_params)\n",
    "adam = Adam()\n",
    "@btime train_cnn(x, y, graph, adam); #300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tAverage loss: 1.167\tAverage acc: 0.649\tAverage val acc: 0.48\n",
      "Epoch: 2\tAverage loss: 1.032\tAverage acc: 0.673\tAverage val acc: 0.53\n",
      "Epoch: 3\tAverage loss: 0.994\tAverage acc: 0.677\tAverage val acc: 0.51\n",
      "[0.583, 0.778, 0.667, 0.3, 0.1, 0.9, 0.5, 0.2, 0.5, 0.562]\n",
      "Epoch: 1\tAverage loss: 1.166\tAverage acc: 0.652\tAverage val acc: 0.58\n",
      "Epoch: 2\tAverage loss: 1.081\tAverage acc: 0.654\tAverage val acc: 0.59\n",
      "Epoch: 3\tAverage loss: 1.04\tAverage acc: 0.687\tAverage val acc: 0.51\n",
      "[0.571, 0.429, 0.4, 0.714, 0.778, 0.467, 0.4, 0.273, 0.75, 0.444]\n",
      "Epoch: 1\tAverage loss: 1.251\tAverage acc: 0.596\tAverage val acc: 0.56\n",
      "Epoch: 2\tAverage loss: 1.13\tAverage acc: 0.642\tAverage val acc: 0.52\n",
      "Epoch: 3\tAverage loss: 1.104\tAverage acc: 0.652\tAverage val acc: 0.57\n",
      "[0.556, 0.167, 0.571, 0.778, 0.667, 0.75, 0.25, 0.455, 0.857, 0.455]\n",
      "Epoch: 1\tAverage loss: 1.302\tAverage acc: 0.596\tAverage val acc: 0.52\n",
      "Epoch: 2\tAverage loss: 1.149\tAverage acc: 0.621\tAverage val acc: 0.47\n",
      "Epoch: 3\tAverage loss: 1.223\tAverage acc: 0.618\tAverage val acc: 0.47\n",
      "[0.333, 0.75, 0.286, 0.333, 0.556, 0.75, 0.308, 0.333, 0.4, 0.5]\n",
      "  129.220 s (38118603 allocations: 230.10 GiB)\n"
     ]
    }
   ],
   "source": [
    "x = Variable(3, train_x[:,:,:,1], name=\"x\")\n",
    "y = Variable(1, [train_y[1]], name=\"y\")\n",
    "graph = my_cnn(x, y, cnn_params)\n",
    "adam = Adam()\n",
    "@btime train_cnn(x, y, graph, adam); #1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for train_cnn(::Variable{3}, ::Variable{1}, ::Vector{Node}, ::Adam)\n",
      "  from train_cnn(x, y, grap, adam) in Main at In[23]:1\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(train_cnn)\u001b[39m\n",
      "  x\u001b[36m::Variable{3}\u001b[39m\n",
      "  y\u001b[36m::Variable{1}\u001b[39m\n",
      "  grap\u001b[36m::Vector{Node}\u001b[39m\n",
      "  adam\u001b[36m::Adam\u001b[39m\n",
      "Locals\n",
      "  @_6\u001b[33m\u001b[1m::Union{Nothing, Tuple{Int64, Int64}}\u001b[22m\u001b[39m\n",
      "  #12\u001b[91m\u001b[1m::var\"#12#13\"\u001b[22m\u001b[39m\n",
      "  correct\u001b[36m::Int64\u001b[39m\n",
      "  correct_val\u001b[36m::Int64\u001b[39m\n",
      "  acc_val\u001b[91m\u001b[1m::Union{Float64, Int64}\u001b[22m\u001b[39m\n",
      "  acc_class\u001b[36m::Matrix{Float64}\u001b[39m\n",
      "  acc\u001b[36m::Vector{Float64}\u001b[39m\n",
      "  count_class\u001b[91m\u001b[1m::Vector\u001b[22m\u001b[39m\n",
      "  losses\u001b[36m::Vector{Float64}\u001b[39m\n",
      "  loss\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  val_y\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  val_x\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  ids_val\u001b[36m::Vector{Int64}\u001b[39m\n",
      "  no_val\u001b[36m::Int64\u001b[39m\n",
      "  data_y\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  data_x\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  ids\u001b[36m::Vector{Int64}\u001b[39m\n",
      "  epochs\u001b[36m::Int64\u001b[39m\n",
      "  no_train\u001b[36m::Int64\u001b[39m\n",
      "  @_25\u001b[36m::Int64\u001b[39m\n",
      "  @_26\u001b[33m\u001b[1m::Union{Nothing, Tuple{Int64, Int64}}\u001b[22m\u001b[39m\n",
      "  e\u001b[36m::Int64\u001b[39m\n",
      "  i\u001b[36m::Int64\u001b[39m\n",
      "  pred\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "Body\u001b[36m::Vector{Node}\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m        (no_train = 1000)\n",
      "\u001b[90m│  \u001b[39m        (epochs = 3)\n",
      "\u001b[90m│  \u001b[39m %3   = (1:60000)\u001b[36m::Core.Const(1:60000)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (ids = Main.rand(%3, no_train::Core.Const(1000)))\n",
      "\u001b[90m│  \u001b[39m        (data_x = Base.getindex(Main.train_x, Main.:(:), Main.:(:), Main.:(:), ids))\n",
      "\u001b[90m│  \u001b[39m        (data_y = Base.getindex(Main.train_y, ids))\n",
      "\u001b[90m│  \u001b[39m        (no_val = 100)\n",
      "\u001b[90m│  \u001b[39m %8   = (1:10000)\u001b[36m::Core.Const(1:10000)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (ids_val = Main.rand(%8, no_val::Core.Const(100)))\n",
      "\u001b[90m│  \u001b[39m        (val_x = Base.getindex(Main.test_x, Main.:(:), Main.:(:), Main.:(:), ids_val))\n",
      "\u001b[90m│  \u001b[39m        (val_y = Base.getindex(Main.test_y, ids_val))\n",
      "\u001b[90m│  \u001b[39m        (loss = 0)\n",
      "\u001b[90m│  \u001b[39m        (losses = Main.zeros(epochs::Core.Const(3)))\n",
      "\u001b[90m│  \u001b[39m %14  = Main.:(var\"#12#13\")\u001b[36m::Core.Const(var\"#12#13\")\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %15  = Core.typeof(val_y)\u001b[91m\u001b[1m::DataType\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %16  = Core.apply_type(%14, %15)\u001b[91m\u001b[1m::Type{var\"#12#13\"{_A}} where _A\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (#12 = %new(%16, val_y))\n",
      "\u001b[90m│  \u001b[39m %18  = #12\u001b[91m\u001b[1m::var\"#12#13\"\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %19  = (0:9)\u001b[36m::Core.Const(0:9)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %20  = Base.Generator(%18, %19)\u001b[91m\u001b[1m::Base.Generator{UnitRange{Int64}}\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (count_class = Base.collect(%20))\n",
      "\u001b[90m│  \u001b[39m        (acc = Main.zeros(epochs::Core.Const(3)))\n",
      "\u001b[90m│  \u001b[39m        (acc_class = Main.zeros(10, epochs::Core.Const(3)))\n",
      "\u001b[90m│  \u001b[39m        (acc_val = 0)\n",
      "\u001b[90m│  \u001b[39m        (correct_val = 0)\n",
      "\u001b[90m│  \u001b[39m        (correct = 0)\n",
      "\u001b[90m│  \u001b[39m %27  = (1:epochs::Core.Const(3))\u001b[36m::Core.Const(1:3)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (@_6 = Base.iterate(%27))\n",
      "\u001b[90m│  \u001b[39m %29  = (@_6::Core.Const((1, 1)) === nothing)\u001b[36m::Core.Const(false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %30  = Base.not_int(%29)\u001b[36m::Core.Const(true)\u001b[39m\n",
      "\u001b[90m└──\u001b[39m        goto #9 if not %30\n",
      "\u001b[90m2 ┄\u001b[39m        Core.NewvarNode(:(@_25))\n",
      "\u001b[90m│  \u001b[39m %33  = @_6\u001b[36m::Tuple{Int64, Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (e = Core.getfield(%33, 1))\n",
      "\u001b[90m│  \u001b[39m %35  = Core.getfield(%33, 2)\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (loss = 0)\n",
      "\u001b[90m│  \u001b[39m        (correct = 0)\n",
      "\u001b[90m│  \u001b[39m %38  = (1:no_train::Core.Const(1000))\u001b[36m::Core.Const(1:1000)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (@_26 = Base.iterate(%38))\n",
      "\u001b[90m│  \u001b[39m %40  = (@_26::Core.Const((1, 1)) === nothing)\u001b[36m::Core.Const(false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %41  = Base.not_int(%40)\u001b[36m::Core.Const(true)\u001b[39m\n",
      "\u001b[90m└──\u001b[39m        goto #7 if not %41\n",
      "\u001b[90m3 ┄\u001b[39m %43  = @_26\u001b[36m::Tuple{Int64, Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (i = Core.getfield(%43, 1))\n",
      "\u001b[90m│  \u001b[39m %45  = Core.getfield(%43, 2)\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %46  = Base.getindex(data_x, Main.:(:), Main.:(:), Main.:(:), i)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        Base.setproperty!(x, :output, %46)\n",
      "\u001b[90m│  \u001b[39m %48  = Base.getindex(data_y, i)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %49  = Base.vect(%48)\u001b[91m\u001b[1m::Vector\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        Base.setproperty!(y, :output, %49)\n",
      "\u001b[90m│  \u001b[39m %51  = loss\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %52  = Main.forward!(Main.graph)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (loss = %51 + %52)\n",
      "\u001b[90m│  \u001b[39m %54  = Base.getindex(Main.graph, 19)\u001b[91m\u001b[1m::Node\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %55  = Base.getproperty(%54, :output)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (pred = Main.argmax(%55))\n",
      "\u001b[90m│  \u001b[39m %57  = pred\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %58  = Base.getindex(data_y, i)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %59  = (%58 + 1)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %60  = (%57 == %59)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m└──\u001b[39m        goto #5 if not %60\n",
      "\u001b[90m4 ─\u001b[39m        (correct = correct + 1)\n",
      "\u001b[90m5 ┄\u001b[39m        Main.backward!(Main.graph)\n",
      "\u001b[90m│  \u001b[39m        Main.update_weights!(Main.graph, adam)\n",
      "\u001b[90m│  \u001b[39m        (@_26 = Base.iterate(%38, %45))\n",
      "\u001b[90m│  \u001b[39m %66  = (@_26 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %67  = Base.not_int(%66)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m        goto #7 if not %67\n",
      "\u001b[90m6 ─\u001b[39m        goto #3\n",
      "\u001b[90m7 ┄\u001b[39m %70  = (loss / no_train::Core.Const(1000))\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        Base.setindex!(losses, %70, e)\n",
      "\u001b[90m│  \u001b[39m %72  = (correct / no_train::Core.Const(1000))\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        Base.setindex!(acc, %72, e)\n",
      "\u001b[90m│  \u001b[39m %74  = Main.validate(x, y, Main.graph, val_x, val_y, no_val::Core.Const(100), count_class, acc_class, e)\u001b[36m::Tuple{Float64, Matrix{Float64}}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %75  = Base.indexed_iterate(%74, 1)\u001b[36m::Core.PartialStruct(Tuple{Float64, Int64}, Any[Float64, Core.Const(2)])\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (acc_val = Core.getfield(%75, 1))\n",
      "\u001b[90m│  \u001b[39m        (@_25 = Core.getfield(%75, 2))\n",
      "\u001b[90m│  \u001b[39m %78  = Base.indexed_iterate(%74, 2, @_25::Core.Const(2))\u001b[36m::Core.PartialStruct(Tuple{Matrix{Float64}, Int64}, Any[Matrix{Float64}, Core.Const(3)])\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        (acc_class = Core.getfield(%78, 1))\n",
      "\u001b[90m│  \u001b[39m %80  = e\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %81  = Base.getindex(losses, e)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %82  = (:digits,)\u001b[36m::Core.Const((:digits,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %83  = Core.apply_type(Core.NamedTuple, %82)\u001b[36m::Core.Const(NamedTuple{(:digits,)})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %84  = Core.tuple(3)\u001b[36m::Core.Const((3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %85  = (%83)(%84)\u001b[36m::Core.Const((digits = 3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %86  = Core.kwfunc(Main.round)\u001b[36m::Core.Const(Base.var\"#round##kw\"())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %87  = (%86)(%85, Main.round, %81)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %88  = Base.getindex(acc, e)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %89  = (:digits,)\u001b[36m::Core.Const((:digits,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %90  = Core.apply_type(Core.NamedTuple, %89)\u001b[36m::Core.Const(NamedTuple{(:digits,)})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %91  = Core.tuple(3)\u001b[36m::Core.Const((3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %92  = (%90)(%91)\u001b[36m::Core.Const((digits = 3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %93  = Core.kwfunc(Main.round)\u001b[36m::Core.Const(Base.var\"#round##kw\"())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %94  = (%93)(%92, Main.round, %88)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %95  = (:digits,)\u001b[36m::Core.Const((:digits,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %96  = Core.apply_type(Core.NamedTuple, %95)\u001b[36m::Core.Const(NamedTuple{(:digits,)})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %97  = Core.tuple(3)\u001b[36m::Core.Const((3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %98  = (%96)(%97)\u001b[36m::Core.Const((digits = 3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %99  = Core.kwfunc(Main.round)\u001b[36m::Core.Const(Base.var\"#round##kw\"())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %100 = (%99)(%98, Main.round, acc_val::Float64)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        Main.println(\"Epoch: \", %80, \"\\tAverage loss: \", %87, \"\\tAverage acc: \", %94, \"\\tAverage val acc: \", %100)\n",
      "\u001b[90m│  \u001b[39m        (@_6 = Base.iterate(%27, %35))\n",
      "\u001b[90m│  \u001b[39m %103 = (@_6 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %104 = Base.not_int(%103)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m        goto #9 if not %104\n",
      "\u001b[90m8 ─\u001b[39m        goto #2\n",
      "\u001b[90m9 ┄\u001b[39m %107 = Base.getindex(acc_class, Main.:(:), epochs::Core.Const(3))\u001b[36m::Vector{Float64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %108 = Base.broadcasted_kwsyntax\u001b[36m::Core.Const(Base.Broadcast.broadcasted_kwsyntax)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %109 = (:digits,)\u001b[36m::Core.Const((:digits,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %110 = Core.apply_type(Core.NamedTuple, %109)\u001b[36m::Core.Const(NamedTuple{(:digits,)})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %111 = Core.tuple(3)\u001b[36m::Core.Const((3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %112 = (%110)(%111)\u001b[36m::Core.Const((digits = 3,))\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %113 = Core.kwfunc(%108)\u001b[36m::Core.Const(Base.Broadcast.var\"#broadcasted_kwsyntax##kw\"())\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m│  \u001b[39m %114 = (%113)(%112, %108, Main.round, %107)\u001b[36m::Core.PartialStruct(Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, Base.Broadcast.var\"#41#42\"{Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:digits,), Tuple{Int64}}}, typeof(round)}, Tuple{Vector{Float64}}}, Any[Core.Const(Base.Broadcast.var\"#41#42\"{Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:digits,), Tuple{Int64}}}, typeof(round)}(Base.Pairs(:digits => 3), round)), Tuple{Vector{Float64}}, Core.Const(nothing)])\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %115 = Base.materialize(%114)\u001b[36m::Vector{Float64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m        Main.println(%115)\n",
      "\u001b[90m└──\u001b[39m        return Main.graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(3, train_x[:,:,:,1], name=\"x\")\n",
    "y = Variable(1, [train_x[1]], name=\"y\")\n",
    "graph = my_cnn(x, y, cnn_params)\n",
    "adam = Adam()\n",
    "@code_warntype  train_cnn(x, y, graph, adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:25\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tAverage loss: 1.263\tAverage acc: 0.66\tAverage val acc: 0.43"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:   1%|█                                        |  ETA: 0:00:18\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:24\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\tAverage loss: 0.775\tAverage acc: 0.75\tAverage val acc: 0.5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:   1%|█                                        |  ETA: 0:00:22\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:24\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\tAverage loss: 0.557\tAverage acc: 0.805\tAverage val acc: 0.44\n",
      "[0.333, 0.6, 0.429, 0.5, 0.273, 0.636, 0.286, 0.111, 0.5, 0.545]\n",
      " 76.749931 seconds (8.92 M allocations: 46.883 GiB, 8.71% gc time, 0.00% compilation time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:25\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tAverage loss: 1.235\tAverage acc: 0.67\tAverage val acc: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:24\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\tAverage loss: 0.818\tAverage acc: 0.71\tAverage val acc: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:22\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\tAverage loss: 0.635\tAverage acc: 0.79\tAverage val acc: 0.51\n",
      "[0.333, 0.9, 0.857, 0.3, 0.0, 0.727, 0.429, 0.333, 0.429, 0.545]\n",
      " 74.455460 seconds (8.91 M allocations: 46.883 GiB, 9.12% gc time, 0.00% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21-element Vector{Any}:\n",
       " var x\n",
       " ┣━ ^ 28×28×1 Array{Float64, 3}\n",
       " ┗━ ∇ 28×28×1 Array{Float64, 3}\n",
       " var k1\n",
       " ┣━ ^ 20×25 Matrix{Float64}\n",
       " ┗━ ∇ 20×25 Matrix{Float64}\n",
       " var b1\n",
       " ┣━ ^ 1×576 Matrix{Float64}\n",
       " ┗━ ∇ 1×576 Matrix{Float64}\n",
       " op (typeof(conv_layer))\n",
       " op (typeof(relu))\n",
       " op (typeof(maxpool_layer))\n",
       " var k2\n",
       " ┣━ ^ 50×25 Matrix{Float64}\n",
       " ┗━ ∇ 50×25 Matrix{Float64}\n",
       " var b2\n",
       " ┣━ ^ 1×64 Matrix{Float64}\n",
       " ┗━ ∇ 1×64 Matrix{Float64}\n",
       " op (typeof(conv_layer))\n",
       " op (typeof(relu))\n",
       " op (typeof(maxpool_layer))\n",
       " op (typeof(flatten))\n",
       " var w3\n",
       " ┣━ ^ 500×800 Matrix{Float64}\n",
       " ┗━ ∇ 500×800 Matrix{Float64}\n",
       " var b3\n",
       " ┣━ ^ 500-element Vector{Float64}\n",
       " ┗━ ∇ 500-element Vector{Float64}\n",
       " op (typeof(dense_layer))\n",
       " var w4\n",
       " ┣━ ^ 10×500 Matrix{Float64}\n",
       " ┗━ ∇ 10×500 Matrix{Float64}\n",
       " var b4\n",
       " ┣━ ^ 10-element Vector{Float64}\n",
       " ┗━ ∇ 10-element Vector{Float64}\n",
       " op (typeof(dense_layer))\n",
       " op (typeof(softmax))\n",
       " var y\n",
       " ┣━ ^ 1-element Vector{Float64}\n",
       " ┗━ ∇ 1-element Vector{Float64}\n",
       " op (typeof(cross_entropy_loss))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time train_cnn()\n",
    "@time train_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(undo::typeof(Base.ensure_rescheduled))",
      "   @ Base .\\task.jl:871",
      " [2] wait()",
      "   @ Base .\\task.jl:931",
      " [3] yield()",
      "   @ Base .\\task.jl:815",
      " [4] oslibuv_flush",
      "   @ C:\\Users\\AGATA\\.julia\\packages\\IJulia\\6TIq1\\src\\stdio.jl:269 [inlined]",
      " [5] flush(io::IJulia.IJuliaStdio{Base.PipeEndpoint})",
      "   @ IJulia C:\\Users\\AGATA\\.julia\\packages\\IJulia\\6TIq1\\src\\stdio.jl:276",
      " [6] flush_all()",
      "   @ IJulia C:\\Users\\AGATA\\.julia\\packages\\IJulia\\6TIq1\\src\\stdio.jl:259",
      " [7] display(d::IJulia.InlineDisplay, x::Plots.Plot{Plots.GRBackend})",
      "   @ IJulia C:\\Users\\AGATA\\.julia\\packages\\IJulia\\6TIq1\\src\\inline.jl:97",
      " [8] display(x::Any)",
      "   @ Base.Multimedia .\\multimedia.jl:328",
      " [9] top-level scope",
      "   @ .\\In[25]:11"
     ]
    }
   ],
   "source": [
    "for i in 1:20\n",
    "    id = rand(1:60000, 1)[1]\n",
    "    img = train_x[:,:,:,id]\n",
    "    img_label = [train_y[id]]\n",
    "    x = Variable(3, img, name=\"x\")\n",
    "    y = Variable(1, img_label, name=\"y\")\n",
    "    graph = my_cnn(x, y, cnn_params)\n",
    "    forward!(graph)\n",
    "    real_label = labels[img_label[1]+1]\n",
    "    pred = labels[argmax(graph[19].output)]\n",
    "    display(plot(Gray.(img[:,:,1]), axis=nothing, size=(300,150), title=\"Real: $real_label    Pred: $pred\"))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
